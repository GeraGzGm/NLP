{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lorem-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional\n",
    "from lorem_text import lorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountVectorizer():\n",
    "    def __init__(self,) -> None:\n",
    "        self.bag_of_words: list = []\n",
    "    \n",
    "    def fit(self, dataset: list[str]) -> None:\n",
    "        \"\"\"\n",
    "        Builds the Bag of Words.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): Dataset that contains the main words.\n",
    "        \"\"\"\n",
    "        dataset = \" \".join(dataset).lower()\n",
    "        self.bag_of_words = dict(zip(*self._get_unique_words(dataset, counts = True)))\n",
    "\n",
    "    def _get_unique_words(self, data: list[str], counts: Optional[bool] = False) -> np.ndarray | tuple[np.ndarray]:\n",
    "        words = re.findall(r'\\b\\w+\\b', data.lower())\n",
    "        return np.unique(words, return_counts = counts)\n",
    "    \n",
    "    @property\n",
    "    def vocabulary_(self) -> dict:\n",
    "        return {k: v for k, v in sorted(self.bag_of_words.items(), key=lambda item: item[1], reverse = True)}\n",
    "    \n",
    "    def transform(self, data: list[str]) -> list:\n",
    "        vector = []\n",
    "        \n",
    "        for sentence in data:\n",
    "            unique_words, counts = self._get_unique_words(sentence, counts = True)\n",
    "            transformed_words = dict(zip(unique_words, counts))\n",
    "            print(transformed_words)\n",
    "            transformed_counts = [transformed_words.get(word, 0) for word, _ in self.bag_of_words.items()]\n",
    "\n",
    "            vector.append(transformed_counts)\n",
    "            \n",
    "        return np.array(vector)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [lorem.paragraphs(10)]\n",
    "X_test = [\"Lorem ipsum is dolor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'totam': 9, 'consectetur': 8, 'ex': 8, 'non': 8, 'ut': 8, 'corrupti': 7, 'dolorum': 7, 'minus': 7, 'numquam': 7, 'perferendis': 7, 'quod': 7, 'voluptas': 7, 'voluptates': 7, 'aut': 6, 'deleniti': 6, 'enim': 6, 'esse': 6, 'est': 6, 'incidunt': 6, 'iusto': 6, 'nisi': 6, 'praesentium': 6, 'quaerat': 6, 'qui': 6, 'quidem': 6, 'voluptatibus': 6, 'a': 5, 'accusamus': 5, 'amet': 5, 'animi': 5, 'aperiam': 5, 'architecto': 5, 'asperiores': 5, 'autem': 5, 'cum': 5, 'dicta': 5, 'dolore': 5, 'doloribus': 5, 'earum': 5, 'eligendi': 5, 'eum': 5, 'excepturi': 5, 'exercitationem': 5, 'fugiat': 5, 'harum': 5, 'in': 5, 'laborum': 5, 'maxime': 5, 'molestiae': 5, 'nam': 5, 'natus': 5, 'perspiciatis': 5, 'quasi': 5, 'quia': 5, 'quo': 5, 'reprehenderit': 5, 'sed': 5, 'sequi': 5, 'sint': 5, 'vel': 5, 'voluptate': 5, 'voluptatum': 5, 'at': 4, 'corporis': 4, 'culpa': 4, 'deserunt': 4, 'ducimus': 4, 'eius': 4, 'error': 4, 'expedita': 4, 'facilis': 4, 'fugit': 4, 'ipsam': 4, 'iste': 4, 'labore': 4, 'magnam': 4, 'molestias': 4, 'nemo': 4, 'nostrum': 4, 'obcaecati': 4, 'officia': 4, 'officiis': 4, 'placeat': 4, 'porro': 4, 'quam': 4, 'quis': 4, 'quisquam': 4, 'repudiandae': 4, 'similique': 4, 'suscipit': 4, 'tempora': 4, 'tempore': 4, 'temporibus': 4, 'velit': 4, 'veniam': 4, 'voluptatem': 4, 'adipisci': 3, 'aspernatur': 3, 'atque': 3, 'beatae': 3, 'commodi': 3, 'consequuntur': 3, 'dignissimos': 3, 'distinctio': 3, 'dolor': 3, 'eos': 3, 'et': 3, 'explicabo': 3, 'id': 3, 'illum': 3, 'impedit': 3, 'ipsa': 3, 'itaque': 3, 'laboriosam': 3, 'laudantium': 3, 'minima': 3, 'mollitia': 3, 'nesciunt': 3, 'nihil': 3, 'nulla': 3, 'omnis': 3, 'pariatur': 3, 'possimus': 3, 'provident': 3, 'quibusdam': 3, 'ratione': 3, 'recusandae': 3, 'reiciendis': 3, 'repellat': 3, 'sapiente': 3, 'sit': 3, 'tenetur': 3, 'ullam': 3, 'unde': 3, 'veritatis': 3, 'vitae': 3, 'ab': 2, 'ad': 2, 'alias': 2, 'blanditiis': 2, 'cupiditate': 2, 'delectus': 2, 'dolorem': 2, 'eaque': 2, 'eveniet': 2, 'facere': 2, 'fuga': 2, 'hic': 2, 'illo': 2, 'inventore': 2, 'ipsum': 2, 'iure': 2, 'libero': 2, 'magni': 2, 'necessitatibus': 2, 'neque': 2, 'odit': 2, 'quae': 2, 'quos': 2, 'rem': 2, 'repellendus': 2, 'rerum': 2, 'saepe': 2, 'soluta': 2, 'sunt': 2, 'vero': 2, 'accusantium': 1, 'adipisicing': 1, 'aliqua': 1, 'aliquam': 1, 'aliquid': 1, 'aliquip': 1, 'anim': 1, 'aute': 1, 'cillum': 1, 'commodo': 1, 'consequat': 1, 'cumque': 1, 'cupidatat': 1, 'do': 1, 'dolores': 1, 'duis': 1, 'ea': 1, 'eiusmod': 1, 'elit': 1, 'eu': 1, 'excepteur': 1, 'exercitation': 1, 'incididunt': 1, 'irure': 1, 'laboris': 1, 'lorem': 1, 'magna': 1, 'maiores': 1, 'minim': 1, 'mollit': 1, 'nobis': 1, 'nostrud': 1, 'occaecat': 1, 'odio': 1, 'optio': 1, 'proident': 1, 'tempor': 1, 'ullamco': 1}\n",
      "{'dolor': 1, 'ipsum': 1, 'is': 1, 'lorem': 1}\n",
      "Encoded Document is:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "countvec = CountVectorizer()\n",
    "countvec.fit(X_train)\n",
    "\n",
    "vocab = countvec.vocabulary_\n",
    "print(\"Vocabulary:\", vocab)\n",
    "\n",
    "vector = countvec.transform(X_test)\n",
    "print(\"Encoded Document is:\")\n",
    "\n",
    "for counts in vector:\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'lorem': 105, 'ipsum': 93, 'dolor': 45, 'sit': 177, 'amet': 11, 'consectetur': 28, 'adipisicing': 5, 'elit': 59, 'sed': 173, 'do': 44, 'eiusmod': 57, 'tempor': 181, 'incididunt': 88, 'ut': 190, 'labore': 99, 'et': 65, 'dolore': 46, 'magna': 106, 'aliqua': 7, 'enim': 60, 'ad': 3, 'minim': 111, 'veniam': 193, 'quis': 157, 'nostrud': 128, 'exercitation': 72, 'ullamco': 188, 'laboris': 101, 'nisi': 125, 'aliquip': 10, 'ex': 69, 'ea': 53, 'commodo': 27, 'consequat': 29, 'duis': 52, 'aute': 21, 'irure': 94, 'in': 87, 'reprehenderit': 168, 'voluptate': 198, 'velit': 192, 'esse': 63, 'cillum': 25, 'eu': 66, 'fugiat': 79, 'nulla': 130, 'pariatur': 140, 'excepteur': 70, 'sint': 176, 'occaecat': 133, 'cupidatat': 36, 'non': 127, 'proident': 147, 'sunt': 179, 'culpa': 33, 'qui': 153, 'officia': 136, 'deserunt': 40, 'mollit': 116, 'anim': 12, 'id': 83, 'est': 64, 'laborum': 102, 'architecto': 15, 'neque': 122, 'numquam': 131, 'cum': 34, 'perspiciatis': 142, 'molestiae': 114, 'tenetur': 185, 'voluptatibus': 201, 'magni': 108, 'omnis': 138, 'aliquid': 9, 'harum': 81, 'eum': 67, 'nam': 118, 'ipsa': 91, 'porro': 144, 'quibusdam': 155, 'quidem': 156, 'illo': 84, 'tempore': 183, 'eius': 56, 'impedit': 86, 'quasi': 152, 'voluptates': 200, 'dignissimos': 42, 'corrupti': 32, 'iste': 95, 'temporibus': 184, 'ducimus': 51, 'vel': 191, 'natus': 119, 'eligendi': 58, 'nostrum': 129, 'ab': 0, 'nemo': 121, 'perferendis': 141, 'illum': 85, 'incidunt': 89, 'eos': 61, 'dolorum': 50, 'quod': 160, 'minus': 113, 'quo': 159, 'quaerat': 150, 'error': 62, 'dicta': 41, 'provident': 148, 'quam': 151, 'praesentium': 146, 'totam': 186, 'laudantium': 103, 'maxime': 110, 'veritatis': 194, 'dolorem': 47, 'nesciunt': 123, 'molestias': 115, 'suscipit': 180, 'autem': 22, 'adipisci': 4, 'deleniti': 39, 'exercitationem': 73, 'mollitia': 117, 'libero': 104, 'repellat': 166, 'saepe': 171, 'earum': 55, 'consequuntur': 30, 'voluptas': 197, 'corporis': 31, 'officiis': 137, 'similique': 175, 'aperiam': 14, 'doloribus': 49, 'itaque': 96, 'quisquam': 158, 'unde': 189, 'obcaecati': 132, 'quos': 161, 'magnam': 107, 'voluptatem': 199, 'nihil': 124, 'vitae': 196, 'fugit': 80, 'cumque': 35, 'beatae': 23, 'laboriosam': 100, 'quae': 149, 'tempora': 182, 'accusamus': 1, 'animi': 13, 'facilis': 77, 'excepturi': 71, 'ipsam': 92, 'cupiditate': 37, 'eaque': 54, 'asperiores': 16, 'necessitatibus': 120, 'rerum': 170, 'maiores': 109, 'at': 18, 'voluptatum': 202, 'placeat': 143, 'aut': 20, 'repellendus': 167, 'odio': 134, 'commodi': 26, 'ullam': 187, 'vero': 195, 'distinctio': 43, 'quia': 154, 'soluta': 178, 'repudiandae': 169, 'delectus': 38, 'possimus': 145, 'eveniet': 68, 'reiciendis': 164, 'blanditiis': 24, 'aliquam': 8, 'accusantium': 2, 'facere': 76, 'sequi': 174, 'fuga': 78, 'expedita': 74, 'iusto': 98, 'rem': 165, 'odit': 135, 'atque': 19, 'ratione': 162, 'aspernatur': 17, 'alias': 6, 'dolores': 48, 'recusandae': 163, 'inventore': 90, 'minima': 112, 'sapiente': 172, 'explicabo': 75, 'iure': 97, 'optio': 139, 'nobis': 126, 'hic': 82}\n",
      "Encoded Document is:\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "countvec.fit(X_train)\n",
    "\n",
    "vocab = countvec.vocabulary_\n",
    "print(\"Vocabulary:\", vocab)\n",
    "\n",
    "vector = countvec.transform(X_test)\n",
    "print(\"Encoded Document is:\")\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ThisOne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
