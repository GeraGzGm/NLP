{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lorem-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional\n",
    "from lorem_text import lorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountVectorizer():\n",
    "    def __init__(self,) -> None:\n",
    "        self.bag_of_words: list = []\n",
    "    \n",
    "    def fit(self, dataset: list[str]) -> None:\n",
    "        \"\"\"\n",
    "        Builds the Bag of Words.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): Dataset that contains the main words.\n",
    "        \"\"\"\n",
    "        dataset = \" \".join(dataset).lower()\n",
    "        self.bag_of_words = dict(zip(*self._get_unique_words(dataset, counts = True)))\n",
    "\n",
    "    def _get_unique_words(self, data: list[str], counts: Optional[bool] = False) -> np.ndarray | tuple[np.ndarray]:\n",
    "        words = re.findall(r'\\b\\w+\\b', data.lower())\n",
    "        return np.unique(words, return_counts = counts)\n",
    "    \n",
    "    @property\n",
    "    def vocabulary_(self) -> dict:\n",
    "        return {k: v for k, v in sorted(self.bag_of_words.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "    def transform(self, data: list[str], normalize: Optional[str] = None) -> list:\n",
    "        vector = []\n",
    "        \n",
    "        for sentence in data:\n",
    "            unique_words, counts = self._get_unique_words(sentence, counts = True)\n",
    "            transformed_words = dict(zip(unique_words, counts))\n",
    "            print(transformed_words)\n",
    "            transformed_counts = [transformed_words.get(word, 0) for word, _ in self.bag_of_words.items()]\n",
    "\n",
    "            vector.append(transformed_counts)\n",
    "\n",
    "        matrix = np.array(vector)\n",
    "        if normalize:\n",
    "            matrix = self._normalize(matrix, normalize)\n",
    "        return matrix\n",
    "    \n",
    "    def _normalize(self, matrix: np.ndarray, norm: str) -> np.ndarray:\n",
    "        \"\"\"Normalize the matrix with L1 or L2 norm.\"\"\"\n",
    "        if not norm:\n",
    "            return matrix \n",
    "        \n",
    "        if norm == 'l1':\n",
    "            return matrix / np.sum(np.abs(matrix), axis=1, keepdims=True)\n",
    "        elif norm == 'l2':\n",
    "            return matrix / np.sqrt(np.sum(matrix**2, axis=1, keepdims=True))\n",
    "        return matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [lorem.paragraphs(10)]\n",
    "X_test = [\"Lorem ipsum is dolor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'culpa': 9, 'modi': 9, 'accusantium': 8, 'inventore': 8, 'cum': 7, 'dolore': 7, 'id': 7, 'iste': 7, 'itaque': 7, 'numquam': 7, 'officiis': 7, 'sit': 7, 'alias': 6, 'consequuntur': 6, 'corrupti': 6, 'deserunt': 6, 'enim': 6, 'eos': 6, 'esse': 6, 'fugiat': 6, 'fugit': 6, 'illo': 6, 'in': 6, 'laborum': 6, 'magnam': 6, 'molestiae': 6, 'nulla': 6, 'officia': 6, 'provident': 6, 'reprehenderit': 6, 'ullam': 6, 'vero': 6, 'at': 5, 'commodi': 5, 'dolor': 5, 'doloremque': 5, 'earum': 5, 'ex': 5, 'labore': 5, 'maiores': 5, 'maxime': 5, 'minus': 5, 'neque': 5, 'omnis': 5, 'possimus': 5, 'quod': 5, 'quos': 5, 'recusandae': 5, 'rem': 5, 'similique': 5, 'tenetur': 5, 'voluptas': 5, 'voluptatum': 5, 'aliquid': 4, 'aut': 4, 'beatae': 4, 'consectetur': 4, 'cumque': 4, 'dignissimos': 4, 'dolores': 4, 'error': 4, 'est': 4, 'et': 4, 'excepturi': 4, 'illum': 4, 'incidunt': 4, 'ipsam': 4, 'ipsum': 4, 'molestias': 4, 'nihil': 4, 'non': 4, 'odit': 4, 'optio': 4, 'pariatur': 4, 'perferendis': 4, 'porro': 4, 'quam': 4, 'quis': 4, 'quo': 4, 'repudiandae': 4, 'rerum': 4, 'sunt': 4, 'suscipit': 4, 'temporibus': 4, 'ut': 4, 'velit': 4, 'vitae': 4, 'a': 3, 'adipisci': 3, 'amet': 3, 'aperiam': 3, 'architecto': 3, 'asperiores': 3, 'atque': 3, 'autem': 3, 'blanditiis': 3, 'consequatur': 3, 'cupiditate': 3, 'delectus': 3, 'deleniti': 3, 'distinctio': 3, 'dolorem': 3, 'eaque': 3, 'eius': 3, 'eveniet': 3, 'facere': 3, 'fuga': 3, 'hic': 3, 'ipsa': 3, 'iure': 3, 'laboriosam': 3, 'libero': 3, 'magni': 3, 'minima': 3, 'necessitatibus': 3, 'nisi': 3, 'nobis': 3, 'perspiciatis': 3, 'praesentium': 3, 'quae': 3, 'quaerat': 3, 'quas': 3, 'qui': 3, 'quisquam': 3, 'repellat': 3, 'repellendus': 3, 'sapiente': 3, 'sed': 3, 'sequi': 3, 'sint': 3, 'tempora': 3, 'totam': 3, 'unde': 3, 'vel': 3, 'veniam': 3, 'voluptatibus': 3, 'accusamus': 2, 'animi': 2, 'aspernatur': 2, 'assumenda': 2, 'dolorum': 2, 'ea': 2, 'eligendi': 2, 'exercitationem': 2, 'expedita': 2, 'harum': 2, 'iusto': 2, 'laudantium': 2, 'mollitia': 2, 'nemo': 2, 'nesciunt': 2, 'odio': 2, 'quasi': 2, 'quibusdam': 2, 'reiciendis': 2, 'soluta': 2, 'voluptate': 2, 'voluptates': 2, 'ad': 1, 'adipisicing': 1, 'aliqua': 1, 'aliquam': 1, 'aliquip': 1, 'anim': 1, 'aute': 1, 'cillum': 1, 'commodo': 1, 'consequat': 1, 'corporis': 1, 'cupidatat': 1, 'debitis': 1, 'dicta': 1, 'do': 1, 'doloribus': 1, 'ducimus': 1, 'duis': 1, 'eiusmod': 1, 'elit': 1, 'eu': 1, 'eum': 1, 'excepteur': 1, 'exercitation': 1, 'explicabo': 1, 'facilis': 1, 'incididunt': 1, 'irure': 1, 'laboris': 1, 'lorem': 1, 'magna': 1, 'minim': 1, 'mollit': 1, 'nam': 1, 'natus': 1, 'nostrud': 1, 'nostrum': 1, 'obcaecati': 1, 'occaecat': 1, 'placeat': 1, 'proident': 1, 'saepe': 1, 'tempor': 1, 'tempore': 1, 'ullamco': 1, 'veritatis': 1}\n",
      "{'dolor': 1, 'ipsum': 1, 'is': 1, 'lorem': 1}\n",
      "Encoded Document is:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "countvec = CountVectorizer()\n",
    "countvec.fit(X_train)\n",
    "\n",
    "vocab = countvec.vocabulary_\n",
    "print(\"Vocabulary:\", vocab)\n",
    "\n",
    "vector = countvec.transform(X_test)\n",
    "print(\"Encoded Document is:\")\n",
    "\n",
    "for counts in vector:\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'lorem': 107, 'ipsum': 95, 'dolor': 47, 'sit': 178, 'amet': 10, 'consectetur': 28, 'adipisicing': 4, 'elit': 62, 'sed': 174, 'do': 46, 'eiusmod': 60, 'tempor': 182, 'incididunt': 90, 'ut': 191, 'labore': 101, 'et': 68, 'dolore': 48, 'magna': 108, 'aliqua': 6, 'enim': 63, 'ad': 2, 'minim': 113, 'veniam': 194, 'quis': 159, 'nostrud': 131, 'exercitation': 75, 'ullamco': 189, 'laboris': 103, 'nisi': 128, 'aliquip': 9, 'ex': 72, 'ea': 56, 'commodo': 27, 'consequat': 29, 'duis': 55, 'aute': 21, 'irure': 96, 'in': 89, 'reprehenderit': 169, 'voluptate': 199, 'velit': 193, 'esse': 66, 'cillum': 25, 'eu': 69, 'fugiat': 82, 'nulla': 133, 'pariatur': 143, 'excepteur': 73, 'sint': 177, 'occaecat': 136, 'cupidatat': 37, 'non': 130, 'proident': 150, 'sunt': 180, 'culpa': 34, 'qui': 157, 'officia': 139, 'deserunt': 42, 'mollit': 119, 'anim': 11, 'id': 86, 'est': 67, 'laborum': 104, 'tenetur': 186, 'accusantium': 1, 'reiciendis': 165, 'soluta': 179, 'minus': 115, 'quisquam': 160, 'nobis': 129, 'ullam': 188, 'magnam': 109, 'numquam': 134, 'inventore': 92, 'necessitatibus': 123, 'eveniet': 71, 'nemo': 124, 'fugit': 83, 'corporis': 32, 'illo': 87, 'cum': 35, 'officiis': 140, 'consequatur': 30, 'tempore': 184, 'temporibus': 185, 'provident': 151, 'exercitationem': 76, 'facere': 79, 'vero': 196, 'excepturi': 74, 'dignissimos': 44, 'suscipit': 181, 'nostrum': 132, 'quos': 163, 'natus': 122, 'hic': 85, 'cumque': 36, 'iste': 97, 'quod': 162, 'repellendus': 168, 'magni': 110, 'saepe': 172, 'rerum': 171, 'molestiae': 117, 'blanditiis': 24, 'vitae': 197, 'vel': 192, 'repudiandae': 170, 'eum': 70, 'voluptas': 198, 'earum': 58, 'odit': 138, 'unde': 190, 'perspiciatis': 145, 'placeat': 146, 'quibusdam': 158, 'explicabo': 78, 'similique': 176, 'beatae': 23, 'assumenda': 17, 'illum': 88, 'error': 65, 'sapiente': 173, 'itaque': 98, 'maxime': 112, 'sequi': 175, 'eligendi': 61, 'doloremque': 50, 'maiores': 111, 'deleniti': 41, 'nam': 121, 'rem': 166, 'possimus': 148, 'ipsa': 93, 'delectus': 40, 'iusto': 100, 'consequuntur': 31, 'omnis': 141, 'quas': 155, 'optio': 142, 'incidunt': 91, 'molestias': 118, 'dolorum': 53, 'iure': 99, 'voluptates': 200, 'quasi': 156, 'recusandae': 164, 'autem': 22, 'ducimus': 54, 'porro': 147, 'alias': 5, 'mollitia': 120, 'cupiditate': 38, 'commodi': 26, 'ipsam': 94, 'corrupti': 33, 'tempora': 183, 'quo': 161, 'aliquid': 8, 'aperiam': 13, 'adipisci': 3, 'animi': 12, 'eaque': 57, 'quae': 152, 'perferendis': 144, 'neque': 125, 'nihil': 127, 'odio': 137, 'minima': 114, 'atque': 19, 'quaerat': 153, 'laboriosam': 102, 'quam': 154, 'at': 18, 'architecto': 14, 'modi': 116, 'totam': 187, 'libero': 106, 'voluptatum': 202, 'distinctio': 45, 'eius': 59, 'dolores': 51, 'dolorem': 49, 'repellat': 167, 'expedita': 77, 'aut': 20, 'aspernatur': 16, 'nesciunt': 126, 'eos': 64, 'asperiores': 15, 'voluptatibus': 201, 'laudantium': 105, 'harum': 84, 'fuga': 81, 'praesentium': 149, 'facilis': 80, 'veritatis': 195, 'accusamus': 0, 'doloribus': 52, 'debitis': 39, 'obcaecati': 135, 'aliquam': 7, 'dicta': 43}\n",
      "Encoded Document is:\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "countvec.fit(X_train)\n",
    "\n",
    "vocab = countvec.vocabulary_\n",
    "print(\"Vocabulary:\", vocab)\n",
    "\n",
    "vector = countvec.transform(X_test)\n",
    "print(\"Encoded Document is:\")\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ThisOne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
